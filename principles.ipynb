{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\".env\")\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-4o-mini\"):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=100,\n",
    "        temperature=0.9,\n",
    "        response_format={\n",
    "            \"type\": \"json_object\",\n",
    "            # \"type\": \"text\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    completion = completion.to_dict()\n",
    "\n",
    "    content = completion[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average prompt, average response\n",
    "\n",
    "**Task**: run the following prompt and examine the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Can I have a list of product names for a pair of shoes that can fit any foot size?\n",
    "\"\"\"\n",
    "\n",
    "get_completion(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: what do you think some of the obvious issues with this prompt?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Vague direction**: what style and attributes?\n",
    "2. **Unformatted output**: how many names and in what format?\n",
    "3. **Missing example**: what good names look like?\n",
    "4. **Limited evaluation**: how to determine if a name is good or bad?\n",
    "5. **No task division**: what are the steps involved?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Five Principles of Prompting\n",
    "\n",
    "1. **Give Direction**: describe the desired style in detail, or reference a relevant persona\n",
    "\n",
    "2. **Specify Format**: define what rules to follow, and the required structure of the response\n",
    "\n",
    "3. **Provide Examples**: insert a diverse set of test cases where the task was done correctly\n",
    "\n",
    "4. **Evaluate Quality**: identify errors and rate responses, testing what drives performance\n",
    "\n",
    "5. **Divide Labour**: split tasks into multiple steps, chained together for complex goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. **Give Direction**\n",
    "\n",
    "Human would also struggle to complete this task without a good brief. Imagine what context a human might need for this task and try including it in the prompt.\n",
    "\n",
    "**Strategies**:\n",
    "\n",
    "* Role-playing\n",
    "* Prewarming or internal retrieval\n",
    "* Best advice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Role-playing**: find a persona (who is famous in the training data) to emulate their style\n",
    "\n",
    "**Task**: Use Steve Jobs as a persona to give direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Brainstorm a list of product names for a shoe that fits any foot size, in the style of Steve Jobs?\"\n",
    "get_completion(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prewarming or internal retrieval**: ask chatGPT for best practice advice, then ask it to follow its own advice \n",
    "\n",
    "**Task**: ask chatGPT for advice, then use its advice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Please give me 5 tips for naming products based on expert industry advice\"\n",
    "advice = get_completion(prompt)\n",
    "advice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Using the following advice:\n",
    "\n",
    "{advice}\n",
    "\n",
    "Brainstorm a list of product names for a shoe that fits any foot size?\n",
    "\"\"\"\n",
    "\n",
    "get_completion(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best advice**: take the best advice you can find for the task and use it\n",
    "\n",
    "**Task**: Use the [5 Golden Rules](https://www.brandwatch.com/blog/how-to-name-a-product-our-5-golden-rules/) for naming a product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advice = \"\"\"\n",
    "1. It should be readable and writable\n",
    "If your product name is hard to pronounce, people won’t talk about it and if they can’t write it down (and spell it correctly!) when they hear it, how do you expect them to Google it?\n",
    "\n",
    "Keep it simple and don’t go with any wacky spellings just for the sake of it.\n",
    "\n",
    "2. It should be unique\n",
    "It’s very hard in this day and age to be completely unique, so you can give yourself a bit of leeway, but your product name should at least be unique to your industry.\n",
    "\n",
    "This makes it much easier to get the domain, do well in search and know that when someone says the name, they mean your product.\n",
    "\n",
    "3. It should be short, punchy and memorable\n",
    "The longer the name, the harder it is to grab people.\n",
    "\n",
    "Longer names also mean people resort to abbreviations that you often don’t get to control.\n",
    "\n",
    "4. It should look good written down and sound cool to say\n",
    "You want your product name to jump off the page and stand out next to all the other boring words around it.\n",
    "\n",
    "When someone says it in a sentence it should stand out so everyone around pays attention.\n",
    "\n",
    "5. It should evoke an emotion, feeling or idea\n",
    "Your product name should tie back into what your product is, what the feeling you want people to have when experiencing your product is, and/or what idea are you trying to get across.\n",
    "\n",
    "It should be emotive and inspiring\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Using the following 5 golden rules:\n",
    "\n",
    "{advice}\n",
    "\n",
    "Brainstorm a list of product names for a shoe that fits any foot size?\n",
    "\"\"\"\n",
    "\n",
    "get_completion(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trade-off**: too much direction can cause the model to quickly get into a conflicting combination that it can't resolve. While too much direction can narrow the creativity of the model, too little direction is the more common problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. **Specify Format**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AI models are universal translators! They can translate between:\n",
    "\n",
    "* Languages, for example French to English\n",
    "* Data formats, for example lists to json \n",
    "* Programming languages, for example, for example C# to Python\n",
    "* Natural language and programming languages, for example text to Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Task**: Update the prompt to return the response as a comma-separated list of 5 names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Can I have a list of product names for a pair of shoes that can fit any foot size?\n",
    "\n",
    "Return the response as a comma-separated list of 5 names, in this format: [\"Name 1\", \"Name 2\", \"Name 3\", \"Name 4\", \"Name 5\"]\n",
    "\"\"\"\n",
    "\n",
    "completion = get_completion(prompt)\n",
    "completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Task**: Print the items in the list, one by one\n",
    "* *Hint*: the response is a string list, use `ast.literal_eval` first to convert it into a list object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = ast.literal_eval(completion)\n",
    "\n",
    "for item in completion:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Task**: Update the prompt to return the response as a `json` where the `key` is `\"ProductNames\"` and the value is a comma-separated list of 5 names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Can I have a list of product names for a pair of shoes that can fit any foot size?\n",
    "\n",
    "Return the response as a json in this format: \n",
    "{\"ProductNames\": [\"Name 1\", \"Name 2\", \"Name 3\", \"Name 4\", \"Name 5\"]}\n",
    "\n",
    "Return only json\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "completion = get_completion(prompt)\n",
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = ast.literal_eval(completion)\n",
    "\n",
    "completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Task**: Use the `response_format={\"type\": \"json_object\"}` parameters in the completion request to natively return a `json` response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Can I have a list of product names for a pair of shoes that can fit any foot size?\n",
    "\n",
    "Return the response as a json in this format: \n",
    "{\"ProductNames\": [\"Name 1\", \"Name 2\", \"Name 3\", \"Name 4\", \"Name 5\"]}\n",
    "\"\"\"\n",
    "\n",
    "completion = get_completion(prompt)\n",
    "completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Task**: Print the items in the `ProductNames`\n",
    "* *Hint*: The response is a string json, use `json.loads` to convert it into a json object first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = json.loads(completion)\n",
    "\n",
    "completion[\"ProductNames\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. **Provide Examples**\n",
    "\n",
    "* Our prompts didn't give any examples of what \"good\" outputs look like! A prompt with no examples is called a `zero-shot` prompt which is asking for a lot without giving much in return.\n",
    "\n",
    "* Even adding one example, which is called `one-shot`, helps considerably\n",
    "\n",
    "* It's more common practice to add multiple examples, which is called `few-shot`. The strength of a prompt often comes down to the examples used, especially if you're not a domain expert as providing examples can sometimes be easier than trying to explain what is it that you like about the output to look like "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Task**: experiment with the number of examples, from `zero-shot` to `few-shot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "completion = get_completion(prompt)\n",
    "completion = json.loads(completion)\n",
    "\n",
    "completion[\"ProductNames\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trade-off**: between reliability and creativity. Go past 3-5 examples and the results will become more reliable but less creative. Give similar examples and the results will be much more constrained and less diverse. Lack of diversity and variations can cause a problem in handling edge cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
