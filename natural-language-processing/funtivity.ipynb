{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import spacy\n",
    "from gensim import models\n",
    "from gensim.corpora.dictionary import Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Task: load the `spacy` model `en_core_web_sm-3.7.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Task code here:\"\"\"\n",
    "nlp = spacy.load(\n",
    "    Path(\n",
    "        \"natural-language-processing\",\n",
    "        \"models\",\n",
    "        \"en_core_web_sm-3.7.0\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the `Harry Potter and the Philosopher's Stone` movie transcript in the `data` folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Task: read the text file into a list of lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Task code here:\"\"\"\n",
    "with Path(\n",
    "    \"natural-language-processing\",\n",
    "    \"data\",\n",
    "    \"Harry Potter and the Philosopher's Stone.txt\",\n",
    ").open(\"r\", encoding=\"utf-8\") as file:\n",
    "    lines = file.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Task: keep only relevant lines by \n",
    "    * Removing empty lines. These only have `'\\n'`\n",
    "    * Striping `'\\n'`at the end of lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Task code here:\"\"\"\n",
    "lines_relevant = []\n",
    "\n",
    "for line in lines:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Task: amend your code to keep only relevant lines by:\n",
    "    * Removing empty lines. These only have `'\\n'`\n",
    "    * Removing scene description. These are encapsulated in `[]`\n",
    "    * Striping `'\\n'`at the end of lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Task code here:\"\"\"\n",
    "lines_relevant = []\n",
    "\n",
    "for line in lines:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Task: amend your code to keep only relevant lines by:\n",
    "    * Removing empty lines. These only have `'\\n'`\n",
    "    * Removing scene description. These are encapsulated in `[]`\n",
    "    * Removing scene titles\n",
    "    * Striping `'\\n'`at the end of lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Task code here:\"\"\"\n",
    "lines_relevant = []\n",
    "\n",
    "for line in lines:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Task: amend your code to keep only relevant lines by:\n",
    "    * Removing empty lines. These only have `'\\n'`\n",
    "    * Removing scene description. These are encapsulated in `[]`\n",
    "    * Removing scene titles\n",
    "    * Remove scene descriptions inside lines using regular expressions. These are encapsulated in `[]`\n",
    "    * Striping `'\\n'`at the end of lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Task code here:\"\"\"\n",
    "lines_relevant = []\n",
    "\n",
    "for line in lines:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Task: define a function that uses spacy to tokenize a document, excluding punctuation and stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Task code here:\"\"\"\n",
    "\n",
    "\n",
    "def tokenize(document): ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Task: tokenize each document and create a corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Task 1: get a list of all the characters (these are the first item in each document)\n",
    "* Task 2: get a set of *unique* characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Task 1 code here:\"\"\"\n",
    "characters = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Task 2 code here:\"\"\"\n",
    "characters_unique = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Task 1: build a Gensim dictionary from corpus\n",
    "* Task 2: print out each token and it's id found in the dictionary\n",
    "* Task 3: print out the top 10 most common tokens in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Task 1 code here:\"\"\"\n",
    "dictionary = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Task 2 code here:\"\"\"\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Task 3 code here:\"\"\"\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Task 1: print out each token frequency across all documents (i.e. collection frequencies)\n",
    "* Task 2: print out the number of documents in the corpus \n",
    "* Task 3: print out the number of terms in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Task 1 code here:\"\"\"\n",
    "cfs = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Task 2 code here:\"\"\"\n",
    "num_docs = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Task 3 code here:\"\"\"\n",
    "num_terms = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
